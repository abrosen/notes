\documentclass[10pt,letterpaper]{report}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{tabularx}
%\usepackage{venturis2}


\title{Proposal}
\author{Andrew Rosen}
\begin{document}


\maketitle
\setcounter{tocdepth}{4}
\tableofcontents
\newpage
\chapter{Introduction}

% % % layout
% % % Distributed Computing Challenges
% % % Qualities of DHTs
% % % Hypothesis = These Problems + These qualiteies -> solution
% % % Framework of what these solutions are and what they can do

Distributed Computing is well understood to be the approach to take to solve large problems.  
Many problems can be broken up into multiple parts that can be solved simultaneously, yielding a much quicker result than a single working attacking the problem.
However, there are two broad obstacles in distributed computing.

%Is this 1 problem or two
The first is figuring out how the mechanics of efficiently distributing a problem to multiple workers and asynchronously coordinating their effort.  
The second is creating and maintaining the computation platform itself.


Some specific challenges are:
\begin{description}
	\item[Scalability] - Distributed computing platforms should not be completely static; if the platform would be improved by the addition of a new resource, it should be possible to add that resource.  
	The addition of new workers in a distributed computing framework should be a minimally disruptive process.
    This ties into the network's fault tolerance
	\item[Load-Balancing]  This is one of the most important issues to consider when creating a framework for distributed computing. 
    How do you split up a problem then distribute it so that no single worker is under or over-utilized?
    Failing that, how do you minimize the imbalance in work?
    Is there a way to do so at run time?
    \item[Fault Tolerance]  Even in a network that is expected to remain static for long periods of time, the platform still has to deal with failure.  
    In a centralized environment, hardware failures are common given enough machines.
    We want our platform to gracefully handle failures during runtime and be able to quickly reassign work to other workers.
    In addition, the network should be equally graceful in handling the introduction of new nodes during runtime.
\end{description}

Fortunately, these challenges are not unique to distributed computing but are also obstacles in distributed file storage.  
In particular, distributed file storage applications that utilize Distributed Hash Tables are designed to handle these particular challenges.
\section{Distributed Hash Tables}
%\section{DHTs are better for distributed computing under many circumstances}
Distributed Hash Tables (DHTs) are traditionally used as the backbone of structured Peer-to-Peer (P2P) file-sharing applications.
The largest such application by far is Bittorrent \cite{bittorrent}, which is built using Mainline DHT \cite{mainline},  a  derivative of Kademlia \cite{kademlia}.
The number of users on Bittorrent ranges from 15 million to 27 million users daily, with a turnover of 10 million users a day \cite{mainline}.

Research has largely remained in the file-sharing, and when DHTs are designed, they are geared towards that use case.
However, they are seeing increasing use in other applications, such as using a  DHT as the name resolution layer of a large distributed database.
Research has also been done in using DHTs as an organizing mechanism in distributed machine learning \cite{liparameter}. 
%Cloud Provisioning  (P2P cloud Provisioning).
%\subsection{Notable Advantages Of Distributed Hash Tables}
% %merge up this section

Many DHTs are built upon the assumption that they will be used in some kind of P2P application.
This means a successful application must be deployable on very varied network sizes.
The network must be able to handle members joining and leaving arbitrarily.
The application must be agnostic towards hardware.
The application must be decentralized and split the burden relatively equally among its members.

This leads to DHTs have very specific properties.
While these properties can be individually enumerated, they are greatly intertwined and the division between their impacts can be somewhat arbitrary.

\subsection{Robustness and Fault-Tolerance}
One of the most important assumptions of DHTs is that they are deployed on a non-static network.
DHTs need to be built to account for a high level what is called \textit{churn}.  
Churn refers to the disruption of routing caused by the constant joining and leaving of nodes.
This is mitigated by a few factors.

First, the network is decentralized, with no single node acting as a single point of failure.
This is accomplished by each node in the routing table having a small portion of the both the routing table and the information stored on the DHT (see the Load Balancing property below).

Second is that each DHT has an inexpensive maintenance processes that mitigates the damage caused by churn.
DHTs often integrate a backup process into their protocols so that when a node goes down, one of the neighbors can immediately assume responsibility.
The join process also causes disruption to the network, as affected nodes have adjust their peerlists to accommodating the joiner. 

The last property is that the hash algorithm used to distribute content evenly across the network(again see load balancing) also distributes nodes evenly across the DHT.  
This means that nodes in the same geographic region occupy vastly different positions in the keyspace.  
If an entire geographic region is affected by a network outage, this damage is spread evenly across the DHT, which can be handled.

This property is the most important, as it deals with failure of entire sections of the network, rather than a single node.
Recent research in using DHTs for High End Computing \cite{li2013zht} shows what can happen if we remove this assumption by placing the network that is almost completely static.



\subsection{Load Balancing}
All Distributed Hash Tables use some kind of consistent hashing algorithm to associate nodes and file identifiers with keys.  
These keys are generated by passing the identifiers into a hash function, typically SHA-160.
The chosen hash function is typically large enough to avoid hash collisions and generates keys in a uniform manner. 
The result of this is that as more nodes join the network, the distribution of nodes in the keyspace becomes more uniform, as does the distribution of files.

However, because this is a random process, it is highly unlikely that each node will be spread evenly throughout the network.
This appears to be a weakness, but can be turned into an advantage in heterogenous systems by using \textit{virtual nodes} \cite{godfrey2005heterogeneity} \cite{dynamo}.
When a node joins the network, it joins not at one position, but multiple virtual positions in the network \cite{dynamo}.
Using virtual nodes allows load-balance optimization in a heterogeneous network; more powerful machines can create more virtual nodes and handle more of  the overall responsibility in the network.
Strategies are discussed further in the Heterogeneity subsection.





%While most DHTs follow this scheme, there is some minor variation on how keys are generated.
%Some DHTs can or do use geographic information to generate keys.
%In VHash, keys are not static, but move according to a simplified spring model.

\subsection{Scalability}
In order to maintain scalability, a DHT has to ensure that as the network grows larger:
\begin{itemize}
    \item Churn does not have a disproportionate overhead.
    \item Lookup request speeds (usually measured in hops) grow by a much smaller amount, possibly not at all.
\end{itemize}

Using consistent hashing allows the network to scale up incrementally, adding one node at a time \cite{dynamo}.
In addition, each join operation has minimal impact on the network, since a node affects only its immediate neighbors on a join operation.

Similarly, the only nodes that need to react to a node leaving are immediately.
This is almost instantaneous if the network is using backups.
Other nodes can be notified of the missing node passively through maintenance.

There have been multiple proposed strategies for tackling scalability, and it is these strategies which play the greatest role in driving the variety of DHT architectures. 
Each DHT must strikes a balance between memory cost of the peerlist and lookup time. 
The vast majority of DHTs choose a logartihmic sized routing table
Table \ref{tab:tradeoffs} lists various DHTs and methods of balancing cost.

\subsection{Heterogeneity}
The mechanics behind load balancing assumes nothing about the nature of the hardware it is running on.
The applications that run DHTs, on the other hand, implicitly assume that that the machines composing the network (and running the application) are heterogeneous.


Can't automatically assign work natively (or can you: end project automatic load balancing DHT?)
Can assign work manually with virtual nodes 


DeCandia et al\. discuss various load balancing techinques that were tested on Dynamo \cite{dynamo}.  
Each node was assigned a certain number of tokens and the node would create a virtual node for each token.
The realization DeCandia et al\. had was that there was no reason to use the same scheme for data partitioning and data placement.
DeCandia et al\. introdiced two new strategies which work off assigning nodes equally sized partitions.



\subsection{The consequences of the Properties}
So what are the consequences of these properties?
\begin{itemize}
    \item DHTs can use constistant hashing supplemented by virtual nodes to efficiently load-balance.
	\item DHTs are highly resilient to damage and can handle abnormally high rates of disruption.  This is extremely desirable in a DHT
	\item X is a desirable property in a network for distributed computing by
	\item 
\end{itemize}



%\section{Different or subproblem: Certain DHTs are better at one application than another due to differences}
%\subsection{Design Differences Impacts}
%\subsection{Geometries}
%\subsection{Routing Table Construction}
%\subsection{Implementation Differences Impacts}
%\paragraph{Recursive or iterative seek}


\section{Hypothesis:  problems in distributed computing + solutions =  dissertation topic}

% Distibuted computing platforms need to be able to handle these challenges
% it turns out they are the same challenges as 

\subsection{The Takeaway}


\begin{itemize}
    \item DHTs are extremely good if your problem is embarrassingly parallel
    \item DHTs are agnostic in terms of what hardware it's running on.
    \item
\end{itemize}



\chapter{Background}

% % %united terminology
Many papers use different terms to describe congruent elements of DHTs, as some terms may make sense only in one context.
I shall endeavor to add to confusion by using the following unified terminology:
\begin{enumerate}
	\item[Peerlist] -  The set of all peers that a node knows about.  This is sometimes referred to as the \textit{routing table}, but certain DHTs \cite{tapestry} \cite{pastry} overload the terminology.
	\item[Neighbors] - The subset of peers that are ``closest/adjacent'' to the node in the keyspace, according to the DHT's metric.  In a 1-dimensional ring, such a Chord \cite{chord}, this is the node's \textit{predecessor} and \textit{successor}.
	\item[Fingers] - The subset of the peerlist that the node is not adjacent to.  These are sometimes referred to as long-hops or shortcuts. The other major distinction is that fingers aren't no
	\item[Root Node] - The node responsible for a particular key. 
\end{enumerate}


% % % table
% Perhaps geometries should be included?
% be sure to include join and leave costs.
\begin{table}[h]
	\small
	\centering
	\begin{tabularx}{\textwidth}{ |X|X|X|X|X| }
		\hline
		% Add join leave cost, avgerages and maxs
		DHT & Routing Table Size & Lookup Time & Join/Leave & Comments \\ \hline  
		Chord \cite{chord}, Kademlia \cite{kademlia} & $O(\log n)$ & $O(\log n)$ & & This is where most DHTs fall  \\ \hline
		CAN \cite{can} & $\Omega(2d)$ & $O(n^{\frac{1}{d}})$, average $\frac{d}{4}\cdot n^{\frac{1}{d}}$ & Affects $O(d)$ nodes & $d$ is the number of dimensions \\ \hline
		
		Plaxton-based DHTs, Pastry \cite{pastry}, Tapestry \cite{tapestry} &  & & & \\ \hline
		& & & & \\ \hline  
		ZHT \cite{li2013zht}&   $O(n)$& $O(1)$ &  &Assumes an extremely low churn \\ \hline
	\end{tabularx}
	\caption{The different ratios and their associated DHTs}
	\label{tab:tradeoffs}
\end{table}


% % % Specific DHTs

\chapter{Justification and Why I Think It's Cool}

\section{Why DHTs for distributed computing?}

\cite{malkhi2001viceroy} -  Between congestion, cost of join/leaves, and lookup time there are tradeoffs.  
Optimizing for two can be done but has bad cost.
For example, a balanced binary tree has congestion at root.
\subsection{DHTs well understood}
\subsection{DHTs are Highly used for their intended purposed}
\subsubsection{Bittorrent, WoW}
\section{DHTs are being effectively leveraged for other things besides file sharing already}

\subsubsection{PaaS}
\subsubsection{Load Balancing in the cloud}
\subsubsection{Resource Management in the cloud}
\subsubsection{Computing is a natural extension}

\subsection{DHTs as a volunteer Platform}
Rather than rely on a centralized administrative source,


Decentralized resource discovery.
The system is organized using a P2P system built on Brunet \cite{brunet}.



PonD \cite{leepond}
\subsubsection{Experiment Description}
Implement and compare to Boinc.



\chapter{Possible Experiments and Applications}


\section{MapReduce}

%copied from CHRONUS
Google's MapReduce \cite{mapreduce} paradigm has rapidly become an integral part in the world of data processing and is capable of efficiently executing numerous Big Data programming and data-reduction tasks.  
By using MapReduce, a user can take a large problem, split it into small, equivalent tasks and send those tasks to other processors for computation.  
The results are sent back to the user and combined into one answer.  
MapReduce has proven to be an extremely powerful and versatile tool, providing the framework for using distributed computing to solve a wide variety of problems, such as distributed sorting and creating an inverted index \cite{mapreduce}. 

At it's core, MapReduce \cite{mapreduce} is a system for process key/value pairs, a that statement that equally describes DHTs.
However, MapReduce operates over a different set of assumptions \cite{hadoopAssumptions} than DHTs.
MapReduce platforms are highly centralized and tend to have single points of failure\cite{shvachko2010hadoop} as a result.   
A centralized design assumes that the network is relatively unchanging and does not usually have mechanisms to handle node failure during execution or, conversely, cannot speed up the execution of a job by adding additional workers on the fly.
Finally deploying these systems and developing programs for them has an extremely steep learning curve.

If we make MapReduce operate under the same assumptions as a DHT, we have effectively further abstracted the MapReduce paradigm and created a system that can operate both in a traditional large datacenter or as part of a P2P network.
The system would be highly resistant to failures at any point, scalable, and automatically load-balance. 
The administrator can add any number of heterogeneous nodes to the system to get it operate.

\subsection{Current MapReduce DHT/P2P combos}
There have been a few implementations combining MapReduce with a P2P framework, in varying capacities.  
I will present two here, as well as my own implementation, ChordReduce.

\subsubsection{P2P-MapReduce}
Marozzo et al. \cite{marozzo2012p2p} investigated the issue of fault tolerance in centralized MapReduce architectures such as Hadoop.  
They focused on creating a new P2P based MapReduce architecture built on JXTA called P2P-MapReduce.  
P2P-MapReduce is designed to be more robust at handling node and job failures during execution.

Rather than use a single master node, P2P-MapReduce employs multiple master nodes, each responsible for some job.  
If one of those master nodes fails, another will be ready as a backup to take its place and manage the slave nodes assigned to that job.  
This avoids the single point of failure that Hadoop is vulnerable to. Failures of the slave nodes are handled by the master node responsible for it.

Experimental results were gathered via simulation and compared P2P-MapReduce to a centralized framework. 
Their results showed that while P2P-MapReduce generated an order of magnitude more messages than a centralized approach, the difference rapidly began to shrink at higher rates of churn.  
When looking at actual amounts of data being passed around the network, the bandwidth required by the centralized approach greatly increased as a function of churn, while the distributed approach again remained relatively static in terms of increased bandwidth usage. 
They concluded that P2P-MapReduce would, in general, use more network resources than a centralized approach. 
However, this was an acceptable cost as the P2P-MapReduce would lose less time from node and job failures \cite{marozzo2012p2p}.

\subsubsection{Parralel Processing Framework on a P2P System}
Lee et al.'s work \cite{leemap} draws attention to the fact that a P2P network can be much more than a way to distribute files and demonstrates how to accomplish different tasks using Map and Reduce functions over a P2P network.  
Rather than using Chord, Lee et al. used Symphony \cite{symphony}, another DHT protocol with a ring topology.  
To run a MapReduce job over the Symphony ring, a node is selected by the user to effectively act as the master.  
This ad-hoc master then performs a bounded broadcast over a subsection the ring.  
Each node repeats this broadcast over a subsection of that subsection, resulting in a tree with the first node at the top.  

Map tasks are disseminated evenly throughout the tree and their results are reduced on the way back up to the ad-hoc master node.  
This allows the ring to disseminate Map and Reduce tasks without the need for a coordinator responsible for distributing these tasks and keeping track of them, unlike Hadoop.  
Their experimental results showed that the latency experienced by a centralized configuration is similar to the latency experienced in a completely distributed framework.





\subsubsection{ChordReduce}
ChordReduce is designed as a more abstract framework for MapReduce, able to run on any arbitrary distributed configuration.
ChordReduce leverages the features of distributed hash tables to handle distributed file storage, fault tolerance, and lookup.  
ChordReduce  was designed to ensure that no single node is a point of failure and that there is no need for any node to coordinate the efforts of other nodes during processing.  



\subsection{Experiment Description: Comparison of MapReduce paradigm on different DHTs}
In order to test MapReduce over a DHT, I will do the following:
\begin{itemize}
	\item Implement CAN \cite{can}, Pastry \cite{pastry}, Chord \cite{chord}, Kademlia \cite{kademlia}, VHash, and ZHT \cite{li2013zht} /similar
	\begin{itemize}	
		\item This covers different geometries with different base parameters.
		\item This also necessitates the creation of an extensible DHT framework.
		\item  The DHT should be extended with more powerful search functionality (see distributed database below), and built-in policies for virtual nodes.
		
	\end{itemize}
	\item Compare results with each other and a traditional MapReduce platform, such as Hadoop.
	\item Certain DHTs may be better suited to different problem formulation
	
\end{itemize}



\section{High End Computing}
PonD?
\subsection{Metadata Management}
\subsection{Robustness}

\subsection{Experiment Description:}

\section{Graph Processing on a DHT}
Lookup Graphlab
\subsection{Embedding}

\subsection{Experiment Description:}
\subsection{Distribute the work for solving a graph on a DHT}
\subsection{Comparison to well established or state of the art methods}



\section{Machine Learning Problems on A DHT}


\subsubsection{Bayesian Learning}
\subsection{Experiment Description:}
Take MapReduce machine learning algorithm

\section{Distributed Databases}


Want to find all files that match the criteria?

Simple: Find all files with ``author = John Smith''.  Idiot solution, assign ``author = John Smith'' a hash key,  it's value is a file with all the files with the (that doesn't scale) 


Complex: Processing database queries.   Find all files with age < 20 and niceness >12


\section{Semiautomagic Load Balancing}

\section{Resources}
\subsection{Planetlab}
\subsection{Local Cluster}

\chapter{DHT Background}



\bibliography{notes}
\bibliographystyle{ieeetr}
\end{document}
